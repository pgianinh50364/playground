A challenge in A/B testing is detecting small but meaningful effects, especially when metrics (e.g. bookings per day) have high variance. High variance requires larger sample sizes, increase time and cost.

>_[@Booking.com][https://booking.ai/how-booking-com-increases-the-power-of-online-experiments-with-cuped-995d186fff1d]_
>_Detecting small effects can be challenging. Imagine running an e-commerce website with a typical conversion rate of 2%. Using [Booking.com’s power calculator](https://bookingcom.github.io/powercalculator/) ([open-source code here](https://github.com/bookingcom/powercalculator)), you can discover that detecting a relative change of 1% to your conversion rate will require an experiment with over 12 million users._

![[Pasted image 20250412132830.png]]

## What is CUPED?: 

Introduced by Microsoft researchers, CUPED reduces variance in a metric by leveraging pre-experiment data, improving the **power** of experiments (ability to detect true effects). By adjusting the metric to account for pre-existing patterns, CUPED allows smaller sample sizes or detection of smaller effects without sacrificing reliability.

## Key Idea: 

Variance in a metric often includes components unrelated to the experiment (e.g., some users book more due to prior behavior). CUPED uses pre-experiment data (e.g., past bookings) to explain and remove this variance, tightening the distribution and making differences easier to detect.

### Key Concepts Explained

Here’s a breakdown of the paper’s core ideas, tailored to be accessible yet precise:

1. **Variance in A/B Testing**:
    - Metrics like bookings per property per day vary widely (from 0 to thousands).
    - High variance increases the standard error ($\text{SE} = \frac{\sigma}{\sqrt{n}}$​), making it harder to detect small mean differences ($\delta = \mu_{\text{treatment}} - \mu_{\text{control}}$).
    - Power ($1 - \beta$) depends on: $$\text{Power} \propto \frac{\delta}{\text{SE}}$$ Reducing $\sigma$ (variance) boosts power.

2. **CUPED’s Goal**:
    - CUPED reduces variance by adjusting the metric using a **covariate**—a pre-experiment measurement correlated with the metric but _unaffected by the treatment_.
    - Example: If testing bookings-per-week, use bookings-per-week from before the experiment as the covariate.

3. **How CUPED Works**:
    - **Intuition**: Some users book more consistently (e.g., frequent travelers). This pre-existing behavior explains part of the metric’s variance, unrelated to the experiment. CUPED subtracts this predictable component.
    - **Adjustment Formula** (Booking.com’s version): $Y_{\text{CUPED}} = Y - \theta (X - \bar{X})$  Where:
        - $Y$: Original metric (e.g., bookings during experiment).
        - $X$: Covariate (e.g., pre-experiment bookings).
        - $\bar{X}$: Mean of the covariate.
        - $\theta$: Coefficient minimizing variance of $Y_{\text{CUPED}}$, typically: $\theta = \frac{\text{Cov}(X, Y)}{\text{Var}(X)}$.
    - **Effect**: $Y_{\text{CUPED}}$​ has the same mean as $Y$ (unbiased) but lower variance if $X$ and $Y$ are correlated.

4. **Covariate Method**:
    - Uses continuous covariates (e.g., bookings, clicks) rather than categorical (stratification).
    - Works best when the covariate is the same metric measured pre-experiment, maximizing correlation $\rho_{X,Y}$.
    - Variance reduction: $\text{Var}(Y_{\text{CUPED}}) = \text{Var}(Y) (1 - \rho_{X,Y}^2)$ Higher $\rho_{X,Y}$​ means greater reduction.

5. **Booking.com’s Implementation**:
	![[Pasted image 20250412144045.png]]
    - Adjusts each user’s metric: $Y_{\text{CUPED}} = Y - (X - \bar{X}) \cdot \theta$.
    - Includes $\bar{X}$ to preserve the sample mean for reporting (unlike Microsoft/Netflix, but doesn’t affect group differences).
    - Example: Testing discounts to increase bookings-per-week. Pre-experiment bookings predict post-experiment behavior, so CUPED adjusts for this baseline.

6. **Benefits**:
    - **Increased Power**: Detect smaller effects (e.g., 1% increase in bookings) with the same sample size.
    - **Faster Experiments**: Smaller samples needed, reducing test duration.
    - **Scalability**: Linear model, easy to compute even for massive datasets.

7. **Challenges**:
    - Requires pre-experiment data (not always available for new users).
    - Effectiveness depends on covariate-metric correlation.
    - Missing data (e.g., new users) needs handling (e.g., impute or exclude).

### Mathematical proofs:

Let’s dive into the math behind CUPED, connecting it to statistical testing:

1. **Variance Reduction**:
    - Original metric: $Y$, with $\text{Var}(Y) = \sigma_Y^2$.
    - Covariate: $X$, with $\text{Var}(X) = \sigma_X^2$, $\text{Cov}(X, Y) = \sigma_{XY}$​.
    - CUPED metric: $$Y_{\text{CUPED}} = Y - \theta (X - \bar{X})$$
    - Variance: $$\text{Var}(Y_{\text{CUPED}}) = \text{Var}(Y - \theta X) = \text{Var}(Y) - 2\theta \text{Cov}(X, Y) + \theta^2 \text{Var}(X)$$
    - Minimize $\text{Var}(Y_{\text{CUPED}})$ by setting: $$\theta = \frac{\text{Cov}(X, Y)}{\text{Var}(X)}$$
    - Resulting variance: $$\text{Var}(Y_{\text{CUPED}}) = \text{Var}(Y) \left(1 - \frac{\text{Cov}(X, Y)^2}{\text{Var}(X) \text{Var}(Y)}\right) = \text{Var}(Y) (1 - \rho_{X,Y}^2)$$
    - If $\rho_{X,Y} = 0.7$, variance drops by $0.7^2 = 49\%$.

2. **Unbiasedness**:
    - Expectation: $$E[Y_{\text{CUPED}}] = E[Y] - \theta E[X - \bar{X}] = E[Y]$$Since $E[X - \bar{X}] = 0$, the mean is unchanged, preserving the treatment effect.

3. **Impact on A/B Testing**:
    - In A/B testing, compare means: $\bar{Y}_{\text{treatment,CUPED}} - \bar{Y}_{\text{control,CUPED}}$.
    - Standard error: $$\text{SE}_{\text{CUPED}} = \sqrt{\frac{\text{Var}(Y_{\text{CUPED}})}{n_{\text{treatment}}} + \frac{\text{Var}(Y_{\text{CUPED}})}{n_{\text{control}}}}$$
    - Lower $\text{Var}(Y_{\text{CUPED}})$ reduces $\text{SE}$, increasing the t-statistic: $$t = \frac{\bar{Y}_{\text{treatment,CUPED}} - \bar{Y}_{\text{control,CUPED}}}{\text{SE}_{\text{CUPED}}}$$
    - Higher $t$ lowers the p-value, improving power.

### Connection to Statistical Tests

The article _A Practitioner's Guide to Statistical Tests_ ([@vkteam][https://vkteam.medium.com/practitioners-guide-to-statistical-tests-ed2d580ef04f#1e3b]) evaluates tests like t-tests, Mann-Whitney U, bootstrap, etc., for A/B testing. CUPED enhances these tests by reducing variance before analysis:

- **T-Tests (Student’s/Welch’s)**:
    - CUPED makes t-tests more powerful by lowering $\text{Var}(Y)$
    - If $Y_{\text{CUPED}}$ is normal, apply: $$t = \frac{\bar{Y}_{\text{treatment,CUPED}} - \bar{Y}_{\text{control,CUPED}}}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$$
    - Welch’s t-test is ideal if variances differ post-CUPED.

- **Mann-Whitney U**:
    - For skewed data (e.g., bookings), CUPED may normalize $Y_{\text{CUPED}}$, but if skewness persists, Mann-Whitney U on $Y_{\text{CUPED}}$​ is robust: $$U = n_1 n_2 + \frac{n_1 (n_1 + 1)}{2} - R_{\text{treatment}}$$
    - Reduced variance tightens rank differences.

- **Bootstrap/Permutation**:
    - Bootstrap $\bar{Y}_{\text{treatment,CUPED}} - \bar{Y}_{\text{control,CUPED}}$​ for non-standard metrics.
    - Permutation tests shuffle $Y_{\text{CUPED}}$, benefiting from lower variance.

- **KS Test**:
    - Less relevant, as CUPED focuses on means, not distributions.

- **Log-Transformed T-Test**:
    - If Y Y Y is log-normal, CUPED may replace log-transformation, as it directly reduces variance without altering scale.

**Insight**: CUPED is a preprocessing step, not a test. Apply it to $Y$, then use the VK article’s tests (e.g., Welch’s t-test for normal data, Mann-Whitney U for skewed) on $Y_{\text{CUPED}}$.

### Integration into A/B Testing Steps

Using your earlier question on A/B testing steps, here’s how CUPED fits (bold indicates CUPED-specific additions):

1. **Define Objective and Hypothesis**:
    - Same as before (e.g., increase bookings).
    - **Note covariate availability** (e.g., pre-experiment bookings).
2. **Identify Control and Treatment**:
    - Unchanged (e.g., old vs. new algorithm).
3. **Determine Sample Size**:
    - **Use CUPED in power calculation**:
        - Estimate $\rho_{X,Y}$​ from historical data.
        - Adjust variance: $\sigma_{\text{CUPED}}^2 = \sigma_Y^2 (1 - \rho_{X,Y}^2)$.
        - Recalculate: $$n \approx \frac{2 \sigma_{\text{CUPED}}^2 (z_{1-\alpha/2} + z_{1-\beta})^2}{\delta^2}$$
        - Example: If $\rho = 0.7$, variance drops 49%, halving $n$.
4. **Randomize and Split**:
    - Unchanged, but **ensure pre-experiment data is collected** for all users.
5. **Choose Statistical Test**:
    - **Apply CUPED first**, then select test (e.g., Welch’s t-test for $Y_{\text{CUPED}}$​).
    - **Check $Y_{\text{CUPED}}$ distribution** (may be more normal than $Y$).
    - **Leave metric scores unadjusted for units with missing pre-experiment data**.
6. **Run the Experiment**:
    - **Collect covariate data** alongside the metric.
    - Example: Log bookings-per-week before and during the test.
7. **Analyze Results**:
    - **Compute $Y_{\text{CUPED}}$:
        - Estimate $\theta = \frac{\text{Cov}(X, Y)}{\text{Var}(X)}$​.
        - Adjust: $Y_{\text{CUPED}} = Y - (X - \bar{X}) \cdot \theta$.
    - Run test (e.g., t-test) on $Y_{\text{CUPED}}$​.
    - **Compare with raw analysis** to confirm variance reduction.
8. **Validate and Interpret**:
    - **Check covariate correlation**: $\rho_{X,Y}$ limits CUPED’s benefit.
    - **Handle missing data**: Impute $X$ (e.g., mean) or exclude new users.
9. **Make a Decision**:
    - Same, but CUPED’s lower p-values may clarify borderline cases.
10. **Document and Share**:
    - **Include CUPED details**: Covariate used, $\theta$, variance reduction.
11. **Monitor Post-Implementation**:
    - Unchanged.